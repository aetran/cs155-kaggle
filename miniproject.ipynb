{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try range of parameters for several common machine learning methods to select best parameters by validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_param(clf_id, clf, v):\n",
    "    if clf_id in [1, 2, 4, 5]:\n",
    "        clf.alpha = v\n",
    "    elif clf_id in [3, 6]:\n",
    "        clf.C = v\n",
    "    elif clf_id in [7]:\n",
    "        clf.min_samples_leaf = v\n",
    "    elif clf_id in [8]:\n",
    "        clf.n_neighbors = v\n",
    "    return clf\n",
    "\n",
    "R = 100 #arbitrary random state\n",
    "CLASSIFIERS = {\n",
    "    0: GaussianNB(),\n",
    "    1: MultinomialNB(), #alpha\n",
    "    2: Lasso(), #alpha\n",
    "    3: LogisticRegression(random_state=R), #C\n",
    "    4: Perceptron(random_state=R), #alpha\n",
    "    5: RidgeClassifier(), #alpha\n",
    "    6: SVC(kernel='linear'), #C\n",
    "    7: DecisionTreeClassifier(random_state=R), #min_samples_leaf\n",
    "    8: KNeighborsClassifier(), #n_neighbors\n",
    "    9: NearestCentroid(),    \n",
    "    10: AdaBoostClassifier(random_state=R), #n_estimators 50\n",
    "    11: BaggingClassifier(), #n_estimators 10\n",
    "    12: GradientBoostingClassifier(), #learning_rate 0.1    \n",
    "    13: RandomForestClassifier(), #n_estimators 10\n",
    "    14: LDA(),\n",
    "    15: QDA()\n",
    "    }\n",
    "    \n",
    "C_VALUES = np.power(float(10), range(-3, 3)) #use for C and alpha\n",
    "PARAMS = {\n",
    "    0: [0],    \n",
    "    1: C_VALUES,\n",
    "    2: C_VALUES,\n",
    "    3: C_VALUES,\n",
    "    4: C_VALUES,\n",
    "    5: C_VALUES,\n",
    "    6: C_VALUES,\n",
    "    7: range(4, 30, 2),\n",
    "    8: range(3, 16, 2),\n",
    "    9: [0],\n",
    "    10: [0],\n",
    "    11: [0],\n",
    "    12: [0],\n",
    "    13: [0],\n",
    "    14: [0],\n",
    "    15: [0],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data and try different feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training data \n",
    "M = 1000 # number of features\n",
    "results = []\n",
    "with open('training_data.txt') as inputfile:\n",
    "    for line in inputfile:\n",
    "        results.append(line.strip().split('|'))\n",
    "N_tr = len(results)-1 # number of training examples\n",
    "X_train = np.array([map(float, results[i][0:-1]) for i in range(1, N_tr+1)])\n",
    "Y_tr = np.array([float(results[i][-1]) for i in range(1, N_tr+1)])\n",
    "\n",
    "# feature processing\n",
    "X_fea = {}\n",
    "X_fea[0] = X_train\n",
    "lda = LatentDirichletAllocation(random_state=R, n_components=5).fit(X_train, Y_tr)\n",
    "X_fea[1] = lda.transform(X_train)\n",
    "lda = LatentDirichletAllocation(random_state=R, n_components=10).fit(X_train, Y_tr)\n",
    "X_fea[2] = lda.transform(X_train)\n",
    "lda = LatentDirichletAllocation(random_state=R, n_components=20).fit(X_train, Y_tr)\n",
    "X_fea[3] = lda.transform(X_train)\n",
    "lda = LatentDirichletAllocation(random_state=R, n_components=50).fit(X_train, Y_tr)\n",
    "X_fea[4] = lda.transform(X_train)\n",
    "lda = LatentDirichletAllocation(random_state=R, n_components=100).fit(X_train, Y_tr)\n",
    "X_fea[5] = lda.transform(X_train)\n",
    "tfidf = TfidfTransformer(norm='l2', sublinear_tf=True)\n",
    "X_fea[6] = (tfidf.fit_transform(X_train)).todense()\n",
    "scaled = StandardScaler()\n",
    "for i in range(1, 6):\n",
    "    scaled.fit(X_fea[i], Y_tr)\n",
    "    X_fea[i] = scaled.transform(X_fea[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few simple classifiers with different feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VAL = 0.3\n",
    "best_score = {}\n",
    "for fea_id in X_fea.keys():\n",
    "    X_tr = X_fea[fea_id]\n",
    "   \n",
    "    # training and validation split\n",
    "    Xr, Xv, Yr, Yv = train_test_split(X_tr, Y_tr, test_size=VAL, random_state=R)\n",
    "   \n",
    "    best_score[fea_id] = []\n",
    "    for clf_id in [3, 6, 7, 4, 8]:\n",
    "        clf = CLASSIFIERS[clf_id]\n",
    "        score = []\n",
    "        for v in PARAMS[clf_id]:\n",
    "            clf = set_param(clf_id, clf, v)\n",
    "            clf.fit(Xr, Yr)\n",
    "            score.append(sum(clf.predict(Xv) == Yv)/float(len(Yv)))\n",
    "        best_score[fea_id].append(max(score))\n",
    "        \n",
    "lines = {}\n",
    "for classifier in range(5):\n",
    "    lines[classifier] = ''.join([' & %.3f' % (best_score[x][classifier]) for x in [1,2,3,4,5,6,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding that tf-idf representation provides better scores than LDA representation, proceed with using the tf-idf representation to train and test all the individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = X_fea[6]\n",
    "Xr, Xv, Yr, Yv = train_test_split(X_tr, Y_tr, test_size=VAL, random_state=R)\n",
    "\n",
    "best_output = {}\n",
    "best_param = {}\n",
    "best_err_val = {}\n",
    "best_err_tr = {}\n",
    "for clf_id in CLASSIFIERS.keys():\n",
    "    clf = CLASSIFIERS[clf_id]\n",
    "    score = []\n",
    "    clf_output = []\n",
    "    err_tr = []\n",
    "    for v in PARAMS[clf_id]:\n",
    "        clf = set_param(clf_id, clf, v)\n",
    "        clf.fit(Xr, Yr)\n",
    "        clf_output.append(clf.predict(Xv))\n",
    "        score.append(sum(clf.predict(Xv) == Yv)/float(len(Yv)))\n",
    "        err_tr.append(sum(clf.predict(Xr) == Yr)/float(len(Yr)))\n",
    "    ind = score.index(max(score))\n",
    "    best_output[clf_id] = clf_output[ind]\n",
    "    best_param[clf_id] = PARAMS[clf_id][ind]\n",
    "    best_err_tr[clf_id] = err_tr[ind]\n",
    "    best_err_val[clf_id] = max(score)\n",
    "    print(clf_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test combinations of individual classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensemble methods\n",
    "P = np.array(best_output.values())\n",
    "P = np.delete(P, 2, axis=0)\n",
    "\n",
    "N_CLASSIFIERS = len(CLASSIFIERS)\n",
    "N_VOTES = range(3, N_CLASSIFIERS, 2)\n",
    "\n",
    "ens_best_param = {}\n",
    "ens_best_score = {}\n",
    "ens_err_train = {}\n",
    "\n",
    "for n_votes in N_VOTES:\n",
    "    combinations = list(itertools.combinations(range(15), n_votes))\n",
    "    ens_best_score[n_votes] = 0\n",
    "    for combo in combinations:\n",
    "        o = sum(P[combo, :]) > float(n_votes)/2\n",
    "        ens_score = sum(o == Yv)/float(len(Yv))\n",
    "        if ens_score > ens_best_score[n_votes]:\n",
    "            ens_best_score[n_votes] = ens_score\n",
    "            ens_best_param[n_votes] = combo\n",
    "    print(n_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bagging\n",
    "clf = BaggingClassifier()\n",
    "bag_err_tr = []\n",
    "bag_err_val = []\n",
    "N_ESTIMATORS = range(5, 101, 5)\n",
    "for v in N_ESTIMATORS:\n",
    "    clf.n_estimators = v\n",
    "    clf.fit(Xr, Yr)\n",
    "    bag_err_val.append(sum(clf.predict(Xv) == Yv)/float(len(Yv)))\n",
    "    bag_err_tr.append(sum(clf.predict(Xr) == Yr)/float(len(Yr)))\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(N_ESTIMATORS, bag_err_tr)\n",
    "plt.plot(N_ESTIMATORS, bag_err_val)\n",
    "plt.ylim([0.65, 1])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a final classifier for the test data based on previous experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test data\n",
    "results = []\n",
    "with open('test_data.txt') as inputfile:\n",
    "    for line in inputfile:\n",
    "        results.append(line.strip().split('|'))\n",
    "N_ts = len(results)-1\n",
    "X_test = np.array([map(float, results[i]) for i in range(1, N_ts+1)])\n",
    "\n",
    "# feature processing\n",
    "tfidf = TfidfTransformer(norm='l2', sublinear_tf=True)\n",
    "X_tr = (tfidf.fit_transform(X_train)).todense()\n",
    "X_ts = (tfidf.transform(X_test)).todense()\n",
    "\n",
    "# train final ensemble classifier\n",
    "best_n_votes = [x for x in ens_best_score.keys() if ens_best_score[x] == max(ens_best_score.values())][0]\n",
    "selected_classifiers = list(ens_best_param[best_n_votes])\n",
    "final_output = []\n",
    "for clf_id in selected_classifiers:\n",
    "    clf = CLASSIFIERS[clf_id]\n",
    "    clf = set_param(clf_id, clf, best_param[clf_id])\n",
    "    clf.fit(X_tr, Y_tr)    \n",
    "    final_output.append(clf.predict(X_ts))\n",
    "final_prediction = sum(np.array(final_output)) > float(best_n_votes)/2\n",
    "\n",
    "# write predictions to text file\n",
    "test_id = 0\n",
    "with open('prediction.txt', 'w') as outputfile:\n",
    "    outputfile.write('Id,Prediction\\n')\n",
    "    for item in final_prediction:\n",
    "        test_id += 1\n",
    "        outputfile.write('%s,%.0f\\n' % (test_id,item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda2]",
   "language": "python",
   "name": "Python [anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
